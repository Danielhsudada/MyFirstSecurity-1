# 教科書

```
Python大數據特訓班：資料自動化收集、整理、分析、儲存與應用實戰(附近300分鐘影音教學/範例程式)
作者： 文淵閣工作室   出版社：碁峰  出版日期：2018/07/11
https://www.books.com.tw/products/0010792124
```
```
Python：網路爬蟲與資料分析入門實戰
作者： 林俊瑋, 林修博    出版社：博碩   出版日期：2018/10/04
https://www.books.com.tw/products/0010800867
```

```
https://realpython.com/tutorials/web-scraping/
```
# 使用requests模組
```
import requests
url = 'http://www.google.com'
html = requests.get(url)
html.encoding="utf-8"
if html.status_code == requests.codes.ok:
    print(html.text)
```

### 使用GET 請求::查詢參數
```
import requests
payload = {'key1': 'value1', 'key2': 'value2'}

html = requests.get("http://httpbin.org/get", params=payload)
print(html.url) # http://httpbin.org/get?key1=value1&key2=value2
```

### 使用 POST請求::查詢參數
```
import requests
payload = {'key1': 'value1', 'key2': 'value2'}
html = requests.post("http://httpbin.org/post", data=payload)
print(html.text)
```

# 使用BeautifulSoup模組解析HTML
```
import requests
from bs4 import BeautifulSoup
url = 'http://www.e-happy.com.tw'
html = requests.get(url)
sp = BeautifulSoup(html.text, 'html.parser')
print(sp.title)
```

```
html = """
<html><head><title>網頁標題</title></head>
<p class="header"><h2>文件標題</h2></p>
<div class="content">
    <div class="item1">
        <a href="http://example.com/one" class="red" id="link1">First</a>
        <a href="http://example.com/two" class="red" id="link2">Second</a>
    </div>
    <a href="http://example.com/three" class="blue" id="link3">
        <img src="http://example.com/three.jpg">Third
    </a>
</div>
"""

from bs4 import BeautifulSoup
sp = BeautifulSoup(html,'html.parser') 

print(sp.title) # <title>網頁標題</title>

print(sp.find('h2')) # <h2>文件標題</h2>

print(sp.find_all('a')) 
print(sp.find_all("a", {"class":"red"}))

data1=sp.find("a", {"href":"http://example.com/one"})
print(data1.text) # First

data2 = sp.select("#link1") 
print(data2[0].text) # First
print(data2[0].get("href")) # http://example.com/one
print(data2[0]["href"])     # http://example.com/one

print(sp.find_all(['title','h2'])) # [<title>網頁標題</title>, <h2>文件標題</h2>]

print(sp.select('div img')[0]['src']) # http://example.com/three.jpg
```
```
import requests
from bs4 import BeautifulSoup
payload = {
   'from': 'https://www.ptt.cc/bbs/Gossiping/index.html',
	'yes': 'yes'
}
headers = {
	'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'
}
rs = requests.Session()
rs.post('https://www.ptt.cc/ask/over18', data=payload, headers=headers)
res = rs.get('https://www.ptt.cc/bbs/Gossiping/index.html', headers=headers)

soup = BeautifulSoup(res.text, 'html.parser')
items = soup.select('.r-ent')
for item in items:
    print(item.select('.date')[0].text, item.select('.author')[0].text, item.select('.title')[0].text)
```

# 使用regular expression的技術

>* Pythex: a Python regular expression editor    www.pythex.org

### 使用re模組

### 使用match()方法
```
import re
m = re.match(r'[a-z]+','tem123po')
print(m)

if not m==None:
    print(m.group()) #tem
    print(m.start()) #0
    print(m.end())   #3
    print(m.span())  #(0, 3)
```

### 使用search()方法

```
import re
m = re.search(r'[a-z]+','3tem12po')
print(m) # <_sre.SRE_Match object; span=(1, 4), match='tem'>
if not m==None:
    print(m.group())  # tem
    print(m.start())  # 1
    print(m.end())    # 4
    print(m.span())   # (1,4)
```


### 使用findall()方法

```
import re
m = re.findall(r'[a-z]+','3tem12po')
print(m) # ['tem', 'po']
```


### 使用compileh()方法將常用的regular expression做成物件

```
import re
reobj = re.compile(r'[a-z]+')
m = reobj.findall('3tem12po')
print(m) # ['tem', 'po']
```

### 綜合練習
```
html = """
<div class="content">
    E-Mail：<a href="mailto:mail@test.com.tw">mail</a><br>
    E-Mail2：<a href="mailto:mail2@test.com.tw">mail2</a><br>
    <ul class="price">定價：360元 </ul>
    <img src="http://test.com.tw/p1.jpg">
    <img src="http://test.com.tw/p2.jpg">
    <img src="http://test.com.tw/p3.png">
</div>
"""

import re
from bs4 import BeautifulSoup
sp = BeautifulSoup(html, 'html.parser')

emails = re.findall(r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+',html)
for email in emails:
    print(email)

price=re.findall(r"[\d]+",sp.select('.price')[0].text)[0] #價格
print(price)

regex=re.compile('.*\.jpg')
imglist=sp.find_all("img",{"src":regex})
for img in imglist:
    print(img["src"])
```

# 使用selenium模組

>* pip install selenium

```
from selenium import webdriver

# 會出現 Alert 視窗
url = 'https://www.facebook.com/'
email='您的 Email 帳號'
password='您的密碼'
driver = webdriver.Chrome()

# 取消 Alert 視窗
#url = 'https://www.facebook.com/'
#chrome_options = webdriver.ChromeOptions()
#prefs = {"profile.default_content_setting_values.notifications" : 2}
#chrome_options.add_experimental_option("prefs",prefs)
#driver = webdriver.Chrome(chrome_options=chrome_options)

driver.maximize_window()
driver.get(url)

driver.find_element_by_id('email').send_keys(email)
driver.find_element_by_id('pass').send_keys(password)
driver.find_element_by_id('loginbutton').click()  # 按 登入 鈕

#driver.quit()
```

# 使用pandas模組進行分析

### 讀取各類型檔案
```
import pandas as pd
data = pd.read_csv("out.csv",encoding="utf-8-sig",index_col=0)

print(data)
```

```
import pandas as pd
data = pd.read_excel("out.xlsx",encoding="utf-8-sig",index_col=0)

print(data)
```

```
import pandas as pd
data = pd.read_html("out.html",encoding="utf-8-sig",index_col=0)

print(data[0])
```


```
import pandas as pd
data = pd.read_json("out.json", typ='series')

print(data)
```

### 輸出到各類型檔案
```
import pandas as pd
datas = [[65,92,78,83,70], [90,72,76,93,56], [81,85,91,89,77], [79,53,47,94,80]]
indexs = ["林大明", "陳聰明", "黃美麗", "熊小娟"]
columns = ["國文", "數學", "英文", "自然", "社會"]
df = pd.DataFrame(datas, columns=columns,  index=indexs)
print(df)

df.to_csv('out.csv',encoding="utf-8-sig")
```


```
import pandas as pd
datas = [[65,92,78,83,70], [90,72,76,93,56], [81,85,91,89,77], [79,53,47,94,80]]
indexs = ["林大明", "陳聰明", "黃美麗", "熊小娟"]
columns = ["國文", "數學", "英文", "自然", "社會"]
df = pd.DataFrame(datas, columns=columns,  index=indexs)
print(df)

df.to_excel('out.xlsx',encoding="utf-8-sig")
```


```
import pandas as pd
datas = [[65,92,78,83,70], [90,72,76,93,56], [81,85,91,89,77], [79,53,47,94,80]]
indexs = ["林大明", "陳聰明", "黃美麗", "熊小娟"]
columns = ["國文", "數學", "英文", "自然", "社會"]
df = pd.DataFrame(datas, columns=columns,  index=indexs)
print(df)

df.to_html('out.html')
```


```
import pandas as pd
datas = [[65,92,78,83,70], [90,72,76,93,56], [81,85,91,89,77], [79,53,47,94,80]]
indexs = ["林大明", "陳聰明", "黃美麗", "熊小娟"]
columns = ["國文", "數學", "英文", "自然", "社會"]
df = pd.DataFrame(datas, columns=columns,  index=indexs)
print(df)

df.to_json('out.json',force_ascii=False)
```


